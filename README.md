# ğŸ  House Price Detection â€“ A Regression Project

Welcome to my house price prediction project!  
In this notebook, I built an end-to-end machine learning pipeline to predict house prices using real estate data.  
From data cleaning to model evaluation, every step is documented and explained in detail.

---

## ğŸ“Œ Project Objectives

- ğŸ“‚ Understand and explore the structure of the dataset
- ğŸ§¼ Clean the data and remove outliers that could harm model performance
- ğŸ—ï¸ Apply feature engineering (e.g. house age, renovation status)
- ğŸ“Š Perform Exploratory Data Analysis (EDA) using meaningful visualizations
- ğŸ¤– Train multiple regression models
- âš–ï¸ Compare the models using MAE, RMSE and RÂ²
- ğŸ” Apply log transformation on skewed target values and evaluate the difference
- ğŸ“ˆ Visualize residuals and actual vs predicted prices
- ğŸ” Test model stability with cross-validation

---

## ğŸ§° Technologies & Libraries Used

- **Python 3**  
- **Pandas, NumPy** for data manipulation  
- **Matplotlib, Seaborn** for data visualization  
- **Scikit-learn** for model training and evaluation  
- **XGBoost** for boosting-based regression  
- **Jupyter Notebook** for development

---
## ğŸ“ Project Structure
ğŸ“¦ House Price Detection
â”œâ”€â”€ ğŸ“Š EDA & Preprocessing
â”‚ â”œâ”€â”€ Outlier removal (IQR method)
â”‚ â”œâ”€â”€ Feature creation: house age, has_been_renovated
â”‚ â””â”€â”€ Visualizations: histograms, scatter plots, boxplots
â”œâ”€â”€ ğŸ§  Model Building
â”‚ â”œâ”€â”€ Linear Regression
â”‚ â”œâ”€â”€ Decision Tree
â”‚ â”œâ”€â”€ Random Forest
â”‚ â”œâ”€â”€ Gradient Boosting
â”‚ â””â”€â”€ XGBoost
â”œâ”€â”€ ğŸ“‰ Log Transformation & Re-training
â”‚ â”œâ”€â”€ Log(price) target modeling
â”‚ â”œâ”€â”€ New evaluation metrics
â”‚ â””â”€â”€ Scatter + residual analysis
â”œâ”€â”€ ğŸ” Cross Validation
â”‚ â”œâ”€â”€ 5-Fold CV on log-transformed model
â”‚ â””â”€â”€ Interpretation of negative RÂ² result
â””â”€â”€ README.md

---

## ğŸ“Š Model Performance Comparison

| Model               | MAE       | RMSE      | RÂ² Score |
|--------------------|-----------|-----------|----------|
| Linear Regression  | 66,895    | 104,618   | 0.74     |
| Decision Tree      | 100,565   | 149,387   | 0.46     |
| Random Forest      | 77,455    | 120,018   | 0.65     |
| Gradient Boosting  | 81,956    | 120,997   | 0.65     |
| **XGBoost**        | 71,507    | 112,382   | 0.70     |

---

## ğŸ“‰ Log Transformed Model Performance

- **MAE**: 86,608  
- **RMSE**: 141,672  
- **RÂ²**: 0.518

> After applying log transformation to the target variable, the performance became smoother in terms of prediction spread, but slightly worse in generalization.

---

## ğŸ“‰ Residual Analysis

Residuals (actual â€“ predicted) were mostly centered around zero, with a few larger errors on expensive homes.  
This suggests the model behaves decently but still struggles slightly with high-value predictions.

---

## â— Cross-Validation Results (Log Target)

- **MAE (log)**: 0.34  
- **RMSE (log)**: 1.28  
- **RÂ²**: -0.2056 âŒ

> Although the model performed well on the test split, cross-validation revealed instability.  
> This shows that testing on multiple splits is essential to find out if a model is truly generalizable.

---

## ğŸ§  Key Learnings

- Outlier removal significantly affects regression models  
- Log transformation can help with skewed targets but might backfire in CV  
- RÂ² can be misleading when evaluated on one split â€” CV is essential  
- Visual tools like scatter and residual plots add real value in diagnosing models

---

## ğŸ”® Future Improvements

- ğŸ¯ Apply hyperparameter tuning on XGBoost
- ğŸ” Add external location-based features (e.g. avg. income, neighborhood stats)
- ğŸ§  Try ensemble stacking methods
- ğŸŒ Build a Streamlit or Flask app for deployment
- ğŸ’¡ Add SHAP values for feature interpretability

---

## ğŸ™‹â€â™€ï¸ About Me

**SÃ¼eda Kazan**  
Computer Engineering Student & Data Science Enthusiast  
GitHub: [@suedakzn](https://github.com/suedakzn)  
Kaggle: [@suedakazan](https://www.kaggle.com/suedakazan)

---

## ğŸ”— Links
- ğŸ““ [Kaggle Notebook]() â€“ *(https://www.kaggle.com/code/suedakazan/house-price-prediction)*
